{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote_plus\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b5c703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CourseraScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://www.coursera.org\"\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate, br',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1'\n",
    "        }\n",
    "    \n",
    "    def scrape_courses(self, query, limit=5):\n",
    "        try:\n",
    "            # Construct search URL\n",
    "            search_url = f\"{self.base_url}/search?query={quote_plus(query)}\"\n",
    "            \n",
    "            print(f\"Searching Coursera for: '{query}'\")\n",
    "            print(f\"URL: {search_url}\\n\")\n",
    "            \n",
    "            # Make request\n",
    "            response = requests.get(search_url, headers=self.headers, timeout=15)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse HTML\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            \n",
    "            courses = []\n",
    "            \n",
    "            # Find all course cards - they're in <li> tags with specific classes\n",
    "            course_cards = soup.find_all('li', class_='cds-9')[:limit]\n",
    "            \n",
    "            for idx, card in enumerate(course_cards, 1):\n",
    "                try:\n",
    "                    course_data = self._extract_course_data(card)\n",
    "                    if course_data:\n",
    "                        courses.append(course_data)\n",
    "                        print(f\"{idx}. {course_data['title']}\")\n",
    "                        print(f\"   Provider: {course_data['provider']}\")\n",
    "                        print(f\"   Type: {course_data['type']}\")\n",
    "                        print(f\"   Level: {course_data['level']}\")\n",
    "                        print(f\"   Duration: {course_data['duration']}\")\n",
    "                        if course_data.get('rating'):\n",
    "                            print(f\"   Rating: {course_data['rating']} ({course_data['reviews']})\")\n",
    "                        print(f\"   Link: {course_data['link']}\")\n",
    "                        print()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting course {idx}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            return courses\n",
    "            \n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error making request to Coursera: {e}\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _extract_course_data(self, card):\n",
    "        course = {}\n",
    "        \n",
    "        # Extract title and link\n",
    "        title_link = card.find('a', class_='cds-CommonCard-titleLink')\n",
    "        if title_link:\n",
    "            title_elem = title_link.find('h3', class_='cds-CommonCard-title')\n",
    "            if title_elem:\n",
    "                course['title'] = title_elem.get_text(strip=True)\n",
    "            \n",
    "            # Extract link from href attribute\n",
    "            href = title_link.get('href', '')\n",
    "            course['link'] = f\"{self.base_url}{href}\" if href else 'N/A'\n",
    "            \n",
    "            # Extract aria-label for additional info (contains type)\n",
    "            aria_label = title_link.get('aria-label', '')\n",
    "            if 'COURSE' in aria_label:\n",
    "                course['type'] = 'Course'\n",
    "            elif 'SPECIALIZATION' in aria_label:\n",
    "                course['type'] = 'Specialization'\n",
    "            elif 'PROFESSIONAL CERTIFICATE' in aria_label:\n",
    "                course['type'] = 'Professional Certificate'\n",
    "            else:\n",
    "                course['type'] = 'N/A'\n",
    "        \n",
    "        # Extract provider/partner information\n",
    "        partner_elem = card.find('p', class_='cds-ProductCard-partnerNames')\n",
    "        if partner_elem:\n",
    "            course['provider'] = partner_elem.get_text(strip=True)\n",
    "        else:\n",
    "            course['provider'] = 'N/A'\n",
    "        \n",
    "        # Extract rating and reviews\n",
    "        rating_elem = card.find('span', class_='css-6ecy9b')\n",
    "        if rating_elem and rating_elem.find_parent('div', class_='cds-RatingStat-meter'):\n",
    "            course['rating'] = rating_elem.get_text(strip=True)\n",
    "            \n",
    "            # Find reviews count\n",
    "            reviews_elem = card.find('div', class_='css-vac8rf', string=lambda x: x and 'reviews' in x.lower())\n",
    "            if reviews_elem:\n",
    "                course['reviews'] = reviews_elem.get_text(strip=True)\n",
    "            else:\n",
    "                course['reviews'] = 'N/A'\n",
    "        else:\n",
    "            course['rating'] = 'N/A'\n",
    "            course['reviews'] = 'N/A'\n",
    "        \n",
    "        # Extract metadata (level, duration)\n",
    "        metadata_elem = card.find('div', class_='cds-CommonCard-metadata')\n",
    "        if metadata_elem:\n",
    "            metadata_text = metadata_elem.get_text(strip=True)\n",
    "            parts = metadata_text.split('Â·')\n",
    "            \n",
    "            if len(parts) >= 1:\n",
    "                course['level'] = parts[0].strip()\n",
    "            else:\n",
    "                course['level'] = 'N/A'\n",
    "            \n",
    "            if len(parts) >= 3:\n",
    "                course['duration'] = parts[2].strip()\n",
    "            elif len(parts) >= 2:\n",
    "                course['duration'] = parts[1].strip()\n",
    "            else:\n",
    "                course['duration'] = 'N/A'\n",
    "        else:\n",
    "            course['level'] = 'N/A'\n",
    "            course['duration'] = 'N/A'\n",
    "        \n",
    "        # Extract skills\n",
    "        skills_elem = card.find('p', class_='css-vac8rf')\n",
    "        if skills_elem and skills_elem.find('strong'):\n",
    "            skills_text = skills_elem.get_text(strip=True)\n",
    "            if 'Skills you\\'ll gain:' in skills_text:\n",
    "                skills = skills_text.replace('Skills you\\'ll gain:', '').strip()\n",
    "                course['skills'] = [s.strip() for s in skills.split(',')[:5]]  # First 5 skills\n",
    "            else:\n",
    "                course['skills'] = []\n",
    "        else:\n",
    "            course['skills'] = []\n",
    "        \n",
    "        return course\n",
    "    \n",
    "    def save_to_json(self, courses, filename='coursera_courses.json'):\n",
    "        try:\n",
    "            with open(filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(courses, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"\\nCourses saved to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving to JSON: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562ad54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Coursera for: 'Machine LEarning'\n",
      "URL: https://www.coursera.org/search?query=Machine+LEarning\n",
      "\n",
      "1. Machine Learning\n",
      "   Provider: Multiple educators\n",
      "   Type: Specialization\n",
      "   Level: Beginner\n",
      "   Duration: 1 - 3 Months\n",
      "   Rating: 4.9 (36K reviews)\n",
      "   Link: https://www.coursera.org/specializations/machine-learning-introduction\n",
      "\n",
      "2. Machine Learning with Python\n",
      "   Provider: IBM\n",
      "   Type: Course\n",
      "   Level: Intermediate\n",
      "   Duration: 1 - 3 Months\n",
      "   Rating: 4.7 (18K reviews)\n",
      "   Link: https://www.coursera.org/learn/machine-learning-with-python\n",
      "\n",
      "3. Foundations of Machine Learning\n",
      "   Provider: Coursera\n",
      "   Type: Course\n",
      "   Level: Intermediate\n",
      "   Duration: 1 - 4 Weeks\n",
      "   Rating: N/A (N/A)\n",
      "   Link: https://www.coursera.org/learn/foundations-of-machine-learning-1\n",
      "\n",
      "4. Machine Learning with PyTorch and Scikit-Learn\n",
      "   Provider: Packt\n",
      "   Type: Course\n",
      "   Level: Intermediate\n",
      "   Duration: 3 - 6 Months\n",
      "   Rating: N/A (N/A)\n",
      "   Link: https://www.coursera.org/learn/packt-machine-learning-with-pytorch-and-scikit-learn\n",
      "\n",
      "5. Python for Data Science, AI & Development\n",
      "   Provider: IBM\n",
      "   Type: Course\n",
      "   Level: Beginner\n",
      "   Duration: 1 - 3 Months\n",
      "   Rating: 4.6 (43K reviews)\n",
      "   Link: https://www.coursera.org/learn/python-for-applied-data-science-ai\n",
      "\n",
      "\n",
      "============================================================\n",
      "Found 5 courses\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    scraper = CourseraScraper()\n",
    "    \n",
    "    # Get search query from user\n",
    "    query = input(\"Enter your search query: \").strip()\n",
    "    \n",
    "    if query:\n",
    "        # Scrape top 5 courses\n",
    "        courses = scraper.scrape_courses(query, limit=5)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"Found {len(courses)} courses\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Optionally save to JSON\n",
    "        # if courses:\n",
    "        #     save = input(\"\\nSave results to JSON? (y/n): \").strip().lower()\n",
    "        #     if save == 'y':\n",
    "        #         scraper.save_to_json(courses)\n",
    "    else:\n",
    "        print(\"Please enter a valid search query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd743da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
